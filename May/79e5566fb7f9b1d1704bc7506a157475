It is exactly 100 days to Kenya’s General Election and thousands of political aspirants are traversing the country on daily, pushing their agenda for election or re-election in the 1,846 elective posts.  The official campaign season kicks off on May 29 but despite this, campaigns are at fever pitch, and tens of millions of shillings have already been spent, most recently in the party primaries.  In previous elections, the campaign period was characterised by colourful billboards along major roads and posters covering every possible surface.   Today, the tide has shifted and Kenyan voters are bracing for one of the most contested elections where platforms such as Facebook and WhatsApp are set to play a defining role.  In April, when major political parties conducted their primaries, more than 600 ads were placed on Facebook alone. This is an average of 20 ads per day targeting Kenyan voters along age, sex, residence, social and cultural preferences.  Facebook’s parent company Meta says the platform has invested heavily in recent years to safeguard against the spread of misinformation and hate speech on its platforms that include Instagram and WhatsApp.  “We are constantly looking at how we can uphold and balance between allowing for free expression and at the same time safety of other users,” said Meta Public Policy Director for East and Horn of Africa Mercy Ndegwa.  “In the last year alone, we have spent over Sh565 billion in growing the teams looking at safety and security at Meta and this is a team that has quadrupled to over 40,000 people in the last six years.”  The changes include an authorisation process for advertisers that seek to run ads about elections and politics that clearly identifies the individual or entity that has paid for the ad.  Users are now prompted with pop-ups and context buttons in the event they want to share a link on Facebook while WhatsApp has limited the number of times a user can forward a message to slow down the virality of content.   “Our policy requires that any advertiser who wants to create or edit ads targeting this country that reference political figures, political parties or elections must go through the authorisation process, place “paid for by” disclaimers on ads and have these ads enter the Ad Library,” says Meta on the reviewed policy for ads run in Kenya.  An analysis of the Facebook Ad Library indicates that advertising and campaigns for the August 9 elections started last year during the national voter registration exercise and accelerated during the party primaries.  The vast majority of the ads are benign in nature and standard in tone - politicians and their parties calling for voters to register for the elections; aspirants thanking voters after winning party nominations or playing up recent public appearances, among others.  Despite the reviewed ad policy, however, some of the political ads in the Facebook Ad Library still do not disclose the identity of the person that has paid for them.  News articles or screenshots are also promoted as ads in several instances, and some of them may be difficult for the average user to discern or verify.  For instance, one political ad presented as a news article from a Kenyan blog features photographs of a Woman Representative with the Deputy President and a story making unverified claims about a relationship between the two leaders.  The ad ran for five days between May 13 and May 18, 2021 with up to 40,000 impressions, reaching an estimated audience of more than one million users.  Political parties  The primary target of the ad was young women between the ages of 25 and 34 residing in Nairobi and Rift Valley provinces.  Another ad sponsored by one of Kenya’s leading political parties features the image of a fake ballot paper with five presidential aspirants and their respective party symbols. The ad targeted an estimated audience of over a million users, primarily men and women between 18 and 34 years old living in Nairobi, Rift Valley and Central Provinces.   Section 5(j) of the Elections Offences Act, 2016 outlaws the unauthorised printing or counterfeiting of ballot papers that can be used in an election.  Another gap is the fact that politicians and political party pages can still produce and post and distribute political content on the newsfeed and through the video service, Facebook Live.  Individuals or entities with large followers can thus circumvent the verification of the platform’s political ad policy and spread their content unchecked.   According to Ms Ndegwa, Meta has employed personnel in Kenya to discern nuanced disinformation and hate speech that might slip past the platform’s automatic moderation systems.      “In the case of the Kenyan elections we have scaled up our capacity in trying to make sure we have local teams that have local understanding,” she said.  “Swahili and English tend to be prominently used on our platforms and we have teams that look at and escalate content that could be problematic.”     Facebook has, however, not made public the exact number of content moderators working to police the Kenyan elections or how the platform will work to moderate harmful speech made in vernacular languages.  At the same time, there has been mounting concern and criticisms of exploitation of content moderators that Meta hires through third-party agreements.  Last month, Meta was issued with a demand letter alongside Samasource Kenya, a third party contractor hired to provide content moderation services for Facebook.  The legal demand by Nzili and Sumbi Advocates was drawn on behalf of Daniel Motaung, a former content moderator from South Africa allegedly fired by Samasource in violation of labour rights.           The demand letter seen by The Standard accuses Facebook and Samasource of luring Mr Motaung and his colleagues for a content moderation job without informing them of the nature of the posts they would be moderating. “The advertisement misrepresented the role, and caused our client to understand that it was administrative,” says the demand letter.  “No disclosure was given that the content moderators being sought were to work as Facebook content moderators.”  Samasource and Meta are also accused of neglecting the mental well-being of the moderators employed to review and remove content that is often graphic and disturbing from the platform.   “Sama and Meta failed to prepare our client for the kind of job he was to do and its effects,” the letter says.  By Winfrey Owino | 1 hour ago By Patrick Alushula | 2 hours ago By Frankline Sunday | 14 hours ago By Macharia Kamau | 1 day ago